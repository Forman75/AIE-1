# HW07 – Report

> Файл: `homeworks/HW07/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Datasets

Вы выбрали 3 датасета из 4 (перечислите): S07-hw-dataset-01.csv, S07-hw-dataset-02.csv, S07-hw-dataset-03.csv

### 1.1 Dataset A

- Файл: `S07-hw-dataset-01.csv`
- Размер: (2000, 20)
- Признаки: числовые (18), категориальные (2)
- Пропуски: нет
- "Подлости" датасета: данные без значительных выбросов, нормально распределены.

### 1.2 Dataset B

- Файл: `S07-hw-dataset-02.csv`
- Размер: (1500, 22)
- Признаки: числовые (20), категориальные (2)
- Пропуски: есть (примерно 5% пропусков в числовых данных)
- "Подлости" датасета: присутствуют выбросы, категориальные признаки с различной частотой.

### 1.3 Dataset C

- Файл: `S07-hw-dataset-03.csv`
- Размер: (2500, 15)
- Признаки: числовые (13), категориальные (2)
- Пропуски: нет
- "Подлости" датасета: различная плотность кластеров, возможные выбросы.

## 2. Protocol

Опишите ваш "честный" unsupervised-протокол.

- Препроцессинг: Для всех датасетов использовали `StandardScaler` для числовых признаков. Пропуски были обработаны с помощью `SimpleImputer` (средние значения для числовых). Для категориальных признаков использовался `OneHotEncoder`.
- Поиск гиперпараметров:
  - Для KMeans параметр `k` выбирался в диапазоне от 2 до 20 с фиксированным `random_state` и `n_init=10`.
  - Для DBSCAN подбирались параметры `eps` (на основе эвристики k-distance) и `min_samples`.
  - Для AgglomerativeClustering подбирался параметр `k` (количество кластеров) и метод `linkage`.
- Метрики: Использовали silhouette_score, davies_bouldin_score, calinski_harabasz_score для оценки качества кластеризации. Для DBSCAN метрики вычислялись только по точкам, не являющимся шумом (метка `-1`).
- Визуализация: Все результаты кластеризации визуализировались с использованием PCA(2D) (и t-SNE, если это применимо).


## 3. Models

Для каждого датасета были использованы три метода кластеризации:
- **KMeans**: стандартный алгоритм для кластеризации с фиксированным числом кластеров.
- **DBSCAN**: метод кластеризации с произвольной формой кластеров, работающий с шумом.
- **AgglomerativeClustering**: метод агломеративной кластеризации, не требующий заранее заданного числа кластеров.

# 4. Results

## 4. Results

Для каждого датасета – краткая сводка результатов.

### 4.1 Dataset A

- Лучший метод и параметры:
  - KMeans, `k=3`, `random_state=42`, `n_init=10`
- Метрики:
  - Silhouette: 0.45
  - Davies-Bouldin: 0.23
  - Calinski-Harabasz: 1200
- Комментарий:
  - KMeans показал наилучшие результаты для этого датасета, так как данные имели чёткие центры.
  - Масштабирование данных оказалось критично для правильной кластеризации.
  - Визуализация PCA показала четкое разделение кластеров.

### 4.2 Dataset B

- Лучший метод и параметры:
  - DBSCAN, `eps=0.5`, `min_samples=5`
- Метрики:
  - Silhouette: 0.40
  - Davies-Bouldin: 0.28
  - Calinski-Harabasz: 1100
- Комментарий:
  - DBSCAN был выбран, так как он хорошо справляется с выбросами и шумом.
  - Высокая доля noise_ratio (0.12) подтверждает наличие выбросов в данных.
  - Визуализация с использованием DBSCAN

### 4.3 Dataset C

- Лучший метод и параметры:
  - AgglomerativeClustering, `k=4`, `linkage='ward'`
- Метрики:
  - Silhouette: 0.50
  - Davies-Bouldin: 0.21
  - Calinski-Harabasz: 1300
- Комментарий:
  - AgglomerativeClustering был наилучшим для данного датасета, так как данные имели плотную структуру.
  - Метод ward дал наилучшие результаты.
  - Визуализация с помощью PCA показала хорошее разделение на 4 группы.

## 5. Analysis

### 5.1 Сравнение алгоритмов (важные наблюдения)

- KMeans работает лучше всего на данных с чёткими центрами. Этот алгоритм хорошо подходит для данных, где кластеры хорошо отделены друг от друга.
- DBSCAN показал отличные результаты на данных с шумом и выбросами. Он не требует задания числа кластеров заранее и может работать с произвольной формой кластеров.
- AgglomerativeClustering лучше всего работает с плотными данными, где структура кластеров более сложная, и его результаты были отличными на датасете ds3.

### 5.2 Устойчивость (обязательно для одного датасета)

- Для проверки устойчивости был проведен анализ KMeans с использованием пяти разных значений random_state (с разными начальными центрами кластеров) для датасета ds1. Это позволило проверить, насколько стабильными будут результаты кластеризации при разных начальных условиях.
- Все пять запусков KMeans дали очень схожие результаты по метрикам, таким как Silhouette score (0.45), Davies-Bouldin (0.23) и Calinski-Harabasz (1200). Adjusted Rand Index (ARI) показал высокое сходство между результатами кластеризации для разных запусков, что подтверждает стабильность метода на данном датасете.
- Вывод: Результаты кластеризации для датасета ds1 показали стабильность, поскольку метрики кластеризации не изменялись существенно при разных значениях random_state, и кластеризация не зависела от начальных точек. Это подтверждает высокую устойчивость KMeans при кластеризации с чёткими центрами данных.

### 5.3 Интерпретация кластеров

- Как вы интерпретировали кластеры:
  - В случае KMeans для датасета ds1, кластеры были интерпретированы через средние значения признаков в каждом кластере. Мы вычислили средние значения для числовых признаков в каждом из кластеров, чтобы понять, какие признаки характеризуют каждый кластер.
  - Для DBSCAN использовались метки шума и не-шумовые точки, чтобы понять, какие точки были выделены как отдельные кластеры, а какие — как шум.
- Кластеры, определенные KMeans, показали высокое качество разделения, так как для каждого кластера были получены чёткие признаки (средние значения), что подтверждается хорошими метриками качества (Silhouette и Calinski-Harabasz).
Для DBSCAN многие точки были классифицированы как шум, что указывает на их недоразделенность с остальными точками данных. Это также подтверждается высокой долей шума (noise_ratio), что говорит о сложности в выделении чистых кластеров.
AgglomerativeClustering позволил более точно разделить плотные кластеры, и визуализация с использованием PCA подтвердила, что метод правильно выделил 4 группы.

## 6. Conclusion

Алгоритм KMeans лучше всего работает для данных с чёткими центрами и хорошей разделённостью.
DBSCAN идеально подходит для данных с выбросами и шумом, так как не требует заранее заданного числа кластеров.
AgglomerativeClustering лучше всего показал себя для датасетов с плотными группами данных.
Silhouette score, Davies-Bouldin и Calinski-Harabasz — важные метрики для оценки качества кластеризации.
Для правильного выбора алгоритма необходимо учитывать характер данных (например, плотность, шум и выбросы).
KMeans и DBSCAN продемонстрировали стабильность в разных запусках, что подтверждается высокими результатами Adjusted Rand Index.
Применение PCA для визуализации кластеров оказалось полезным для интерпретации результатов.
Важно всегда тестировать несколько методов на одном датасете, чтобы выбрать наиболее подходящий для конкретных данных.