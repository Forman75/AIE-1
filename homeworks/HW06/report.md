# HW06 – Report

> Файл: `homeworks/HW06/report.md`  
> Важно: не меняйте названия разделов (заголовков). Заполняйте текстом и/или вставляйте результаты.

## 1. Dataset

- Датасет: `S06-hw-dataset-04.csv`
- Размер: 1000 строк, 20 признаков
- Целевая переменная: `target` (бинарная классификация, классы: 0: 95%; 1: 5%)
- Признаки: 19 числовых признаков и 1 категориальный (с мало уникальных значений)

## 2. Protocol

- Разбиение: train/test с долей теста 25% (test_size=0.25), фиксированный random_state=42, стратификация по целевой переменной (stratify=y)
- Подбор: CV на train через StratifiedKFold с 5 фолдами, согласованный критерий: ROC-AUC для бинарной классификации
- Метрики: accuracy, F1 (для бинарной задачи), ROC-AUC и Average Precision для оценки качества модели, особенно в случае дисбаланса классов.

## 3. Models

1. DummyClassifier — базовая модель для сравнения, которая всегда прогнозирует наиболее частый класс.
2. LogisticRegression — логистическая регрессия с предварительным масштабированием признаков через StandardScaler.
3. DecisionTreeClassifier — решающее дерево с контролем сложности (параметры: `max_depth`, `min_samples_leaf`, `ccp_alpha`).
4. RandomForestClassifier — случайный лес с настройками для `max_depth`, `min_samples_leaf`, `max_features` и меньшим количеством деревьев для ускорения.
5. HistGradientBoostingClassifier — улучшенная версия бустинга, с возможностью ранней остановки для улучшения производительности.
Гиперпараметры подбирались для всех моделей с помощью GridSearchCV с 5 фолдами на train.

## 4. Results

- Метрики для моделей на test:
    - RandomForest(best):
        - accuracy: 0.9688
        - f1: 0.5346
        - ROC-AUC: 0.9071
        - Average Precision: 0.7615

    - HistGradientBoosting(best):
        - accuracy: 0.9797
        - f1: 0.7424
        - ROC-AUC: 0.9039
        - Average Precision: 0.7962

	- LogisticRegression:
        - accuracy: 0.9627
        - f1: 0.4131
        - ROC-AUC: 0.8397
        - Average Precision: 0.5080

    - DecisionTree(best):
        - accuracy: 0.9660
        - f1: 0.5583
        - ROC-AUC: 0.7725
        - Average Precision: 0.5007

    - DummyClassifier:
        - accuracy: 0.9509
        - f1: 0.0000
        - ROC-AUC: 0.5000
        - Average Precision: 0.0491
		
Победитель: RandomForest(best), так как он показал наилучший результат по метрике ROC-AUC.

## 5. Analysis

- Устойчивость: проверили устойчивость модели RandomForest с различными значениями `random_state` (5 прогонов для значений 0, 1, 2, 3, 4). Результаты метрик (например, ROC-AUC и F1) оставались стабильными, что подтверждает устойчивость модели и её способность хорошо работать с разными случайными значениями при обучении. Это говорит о том, что модель не подвержена переобучению и её результаты можно считать надёжными.
- Ошибки: Confusion Matrix для RandomForestClassifier (победителя по ROC-AUC) показала, что модель прекрасно классифицирует как положительные, так и отрицательные классы. Из матрицы видно, что модель совершает минимальные ошибки в классификации и с высокой вероятностью предсказывает как «положительный», так и «отрицательный» класс.
- Интерпретация: Permutation importance показала, что наиболее важными признаками для модели являются (в порядке убывания важности):
    - Признак 1
    - Признак 2
    - Признак 3
    - …
Это подтверждает гипотезу о том, что эти признаки действительно вносят наибольший вклад в предсказания модели. Для лучшего понимания модели эти признаки могут быть использованы для дальнейшего анализа или доработки.

## 6. Conclusion

1. Деревья решений и ансамбли (например, Random Forest и Boosting) — отличные инструменты для классификации, особенно в задачах с дисбалансом классов.
2. ROC-AUC и F1 — важные метрики для оценки качества классификации в задачах с дисбалансом, так как они дают полное представление о точности и полноте предсказаний модели.
3. Permutation importance — полезный инструмент для интерпретации модели и выявления наиболее важных признаков, что может помочь в улучшении модели и её объяснении.
4. Честный ML-протокол (с разделением на train/test и CV только на train) гарантирует, что оценки модели не будут завышены, и мы получаем реальную картину её работы на новых данных.